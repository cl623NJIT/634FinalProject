{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a84b8f",
   "metadata": {},
   "source": [
    "# DS 634 Final Project: Spam Classification\n",
    "\n",
    "Author: Christian Laggui  \n",
    "Date: 4/6/2025  \n",
    "NJIT Email: cl623@njit.edu  \n",
    "\n",
    "Required packages: pip install scikit-learn pandas numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d47f3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages: pip install scikit-learn pandas numpy torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "def get_data_path():\n",
    "    \"\"\"\n",
    "    Returns the path to the data file, working in both scripts and Jupyter notebooks.\n",
    "    Assumes the data file is in the same directory as the script/notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # For regular Python scripts\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        return os.path.join(script_dir, 'spambase.data')\n",
    "    except NameError:\n",
    "        # For Jupyter notebooks\n",
    "        return 'spambase.data'\n",
    "\n",
    "# Load the data\n",
    "# Note: The last column is the target variable (spam = 1, non-spam = 0)\n",
    "try:\n",
    "    data = pd.read_csv(get_data_path(), header=None)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find 'spambase.data'\")\n",
    "    print(\"Please ensure 'spambase.data' is in the same directory as this script/notebook\")\n",
    "    raise\n",
    "\n",
    "# Split into features and target\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # Last column (target)\n",
    "\n",
    "# Scale the features for SVM and GRU\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert data to PyTorch tensors for GRU\n",
    "X_tensor = torch.FloatTensor(X_scaled)\n",
    "y_tensor = torch.FloatTensor(y.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c86142",
   "metadata": {},
   "source": [
    "Code for evaluating Random Forest, SVM, and GRU models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dacdbe40-c1da-47c3-af53-df4fdef2de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for GRU\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# GRU Model\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input for GRU: [batch_size, sequence_length, input_size]\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        return out.squeeze()\n",
    "\n",
    "def evaluate_gru_model(X, y, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates GRU model using 10-fold stratified cross-validation.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        # Split data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = SpamDataset(X_train, y_train)\n",
    "        test_dataset = SpamDataset(X_test, y_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = GRUClassifier(input_size=X.shape[1], hidden_size=64).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        for epoch in range(10):  # 10 epochs per fold\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                predictions = (outputs > 0.5).float().cpu().numpy()\n",
    "                y_pred.extend(predictions)\n",
    "                y_true.extend(batch_y.numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        fpr = fp / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        fnr = fn / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        tss = tpr + tnr - 1\n",
    "        hss = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn)) if ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn)) > 0 else 0\n",
    "\n",
    "        # Calculate additional metrics\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        fdr = fp / (fp + tp) if (fp+tp) > 0 else 0\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn,\n",
    "            'TPR': tpr, 'TNR': tnr, 'FPR': fpr, 'FNR': fnr,\n",
    "            'TSS': tss, 'HSS': hss,\n",
    "            'Prec.': precision, \n",
    "            'NPV': npv,    \n",
    "            'F1': f1,         \n",
    "            'Sens.': tpr,  \n",
    "            'Specif.': tnr,   \n",
    "            'Acc.': accuracy,\n",
    "            'FDR': fdr,\n",
    "            'Confusion Matrix': [[tp, fn], [fp, tn]]  \n",
    "        })\n",
    "        \n",
    "    fold_metrics_df = pd.DataFrame(fold_metrics)\n",
    "    average_metrics = fold_metrics_df.mean(numeric_only=True).to_dict()\n",
    "    average_metrics['Fold'] = 'Average'\n",
    "    average_metrics_df = pd.DataFrame([average_metrics])\n",
    "    results_df = pd.concat([fold_metrics_df, average_metrics_df], ignore_index=True)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Load the data\n",
    "# Note: The last column is the target variable (spam = 1, non-spam = 0)\n",
    "data = pd.read_csv('c:/Users/clagg/Downloads/spambase/spambase.data', header=None)\n",
    "\n",
    "# Split into features and target\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # Last column (target)\n",
    "\n",
    "# Scale the features for SVM\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates a given model using 10-fold stratified cross-validation and calculates\n",
    "    performance metrics.\n",
    "\n",
    "    Args:\n",
    "        model: The machine learning model to evaluate (e.g., RandomForestClassifier, SVC).\n",
    "        X: The feature data.\n",
    "        y: The target data.\n",
    "        model_name (str):  The name of the model\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the performance metrics for each fold\n",
    "                          and the average metrics.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        # Convert indices to numpy arrays if they aren't already\n",
    "        train_index = np.array(train_index)\n",
    "        test_index = np.array(test_index)\n",
    "        \n",
    "        # Handle both numpy arrays and pandas DataFrames\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        else:\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            \n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        fpr = fp / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        fnr = fn / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        tss = tpr + tnr - 1\n",
    "        hss = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn)) if ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn)) > 0 else 0\n",
    "\n",
    "        # Calculate additional metrics\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        fdr = fp / (fp + tp) if (fp + tp) > 0 else 0\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn,\n",
    "            'TPR': tpr, 'TNR': tnr, 'FPR': fpr, 'FNR': fnr,\n",
    "            'TSS': tss, 'HSS': hss,\n",
    "            'Prec.': precision,\n",
    "            'NPV': npv,       \n",
    "            'F1': f1,           \n",
    "            'Sens.': tpr,  \n",
    "            'Specif.': tnr,   \n",
    "            'Acc.': accuracy,     \n",
    "            'FDR': fdr,\n",
    "            'Confusion Matrix': [[tp, fn], [fp, tn]]\n",
    "        })\n",
    "\n",
    "    fold_metrics_df = pd.DataFrame(fold_metrics)\n",
    "    average_metrics = fold_metrics_df.mean(numeric_only=True).to_dict()\n",
    "    average_metrics['Fold'] = 'Average'\n",
    "    average_metrics_df = pd.DataFrame([average_metrics])\n",
    "    results_df = pd.concat([fold_metrics_df, average_metrics_df], ignore_index=True)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fadda",
   "metadata": {},
   "source": [
    "#### Random Forest Implementation\n",
    "The parameters used are:\n",
    "* n_estimators: 100\n",
    "* max_depth: None\n",
    "* random_state: 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6401316b-576d-4cb5-a7f0-6d405dd3c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "   Fold    TP    TN   FP   FN      TPR      TNR    FPR    FNR    TSS    HSS  Prec.    NPV     F1  Sens. Specif.   Acc.    FDR       Confusion Matrix\n",
      "      1 169.0 270.0  9.0 13.0 0.928571 0.967742 0.0323 0.0714 0.8963 0.8998 0.9494 0.9541 0.9389 0.9286  0.9677 0.9523 0.0506  [[169, 13], [9, 270]]\n",
      "      2 169.0 271.0  7.0 13.0 0.928571 0.974820 0.0252 0.0714 0.9034 0.9086 0.9602 0.9542 0.9441 0.9286  0.9748 0.9565 0.0398  [[169, 13], [7, 271]]\n",
      "      3 171.0 271.0  7.0 11.0 0.939560 0.974820 0.0252 0.0604 0.9144 0.9179 0.9607 0.9610 0.9500 0.9396  0.9748 0.9609 0.0393  [[171, 11], [7, 271]]\n",
      "      4 171.0 274.0  5.0 10.0 0.944751 0.982079 0.0179 0.0552 0.9268 0.9313 0.9716 0.9648 0.9580 0.9448  0.9821 0.9674 0.0284  [[171, 10], [5, 274]]\n",
      "      5 169.0 266.0 13.0 12.0 0.933702 0.953405 0.0466 0.0663 0.8871 0.8862 0.9286 0.9568 0.9311 0.9337  0.9534 0.9457 0.0714 [[169, 12], [13, 266]]\n",
      "      6 169.0 271.0  8.0 12.0 0.933702 0.971326 0.0287 0.0663 0.9050 0.9086 0.9548 0.9576 0.9441 0.9337  0.9713 0.9565 0.0452  [[169, 12], [8, 271]]\n",
      "      7 171.0 270.0  9.0 10.0 0.944751 0.967742 0.0323 0.0552 0.9125 0.9134 0.9500 0.9643 0.9474 0.9448  0.9677 0.9587 0.0500  [[171, 10], [9, 270]]\n",
      "      8 168.0 272.0  7.0 13.0 0.928177 0.974910 0.0251 0.0718 0.9031 0.9084 0.9600 0.9544 0.9438 0.9282  0.9749 0.9565 0.0400  [[168, 13], [7, 272]]\n",
      "      9 163.0 270.0  9.0 18.0 0.900552 0.967742 0.0323 0.0994 0.8683 0.8759 0.9477 0.9375 0.9235 0.9006  0.9677 0.9413 0.0523  [[163, 18], [9, 270]]\n",
      "     10 165.0 273.0  6.0 16.0 0.911602 0.978495 0.0215 0.0884 0.8901 0.8988 0.9649 0.9446 0.9375 0.9116  0.9785 0.9522 0.0351  [[165, 16], [6, 273]]\n",
      "Average 168.5 270.8  8.0 12.8 0.929394 0.971308 0.0287 0.0706 0.9007 0.9049 0.9548 0.9549 0.9418 0.9294  0.9713 0.9548 0.0452                    NaN\n"
     ]
    }
   ],
   "source": [
    "# 1. Random Forest Implementation\n",
    "print(\"Random Forest Results:\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "rf_results = evaluate_model(rf_classifier, X, y, \"Random Forest\")\n",
    "print(rf_results.to_string(index=False, formatters={\n",
    "    'Sens.': '{:.4f}'.format,\n",
    "    'Specif.': '{:.4f}'.format,\n",
    "    'Prec.': '{:.4f}'.format,\n",
    "    'NPV': '{:.4f}'.format,\n",
    "    'FPR': '{:.4f}'.format,\n",
    "    'FDR': '{:.4f}'.format,\n",
    "    'FNR': '{:.4f}'.format,\n",
    "    'Acc.': '{:.4f}'.format,\n",
    "    'F1': '{:.4f}'.format,\n",
    "    'TSS': '{:.4f}'.format,\n",
    "    'HSS': '{:.4f}'.format\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5144f98",
   "metadata": {},
   "source": [
    "#### SVM Implementation\n",
    "The parameters used are:\n",
    "* Kernel: RBF\n",
    "* C: 100\n",
    "* random_state: 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "885502e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine Results:\n",
      "   Fold    TP    TN   FP   FN      TPR      TNR    FPR    FNR    TSS    HSS  Prec.    NPV     F1  Sens. Specif.   Acc.    FDR       Confusion Matrix\n",
      "      1 161.0 264.0 15.0 21.0 0.884615 0.946237 0.0538 0.1154 0.8309 0.8356 0.9148 0.9263 0.8994 0.8846  0.9462 0.9219 0.0852 [[161, 21], [15, 264]]\n",
      "      2 164.0 265.0 13.0 18.0 0.901099 0.953237 0.0468 0.0989 0.8543 0.8584 0.9266 0.9364 0.9136 0.9011  0.9532 0.9326 0.0734 [[164, 18], [13, 265]]\n",
      "      3 170.0 264.0 14.0 12.0 0.934066 0.949640 0.0504 0.0659 0.8837 0.8820 0.9239 0.9565 0.9290 0.9341  0.9496 0.9435 0.0761 [[170, 12], [14, 264]]\n",
      "      4 157.0 266.0 13.0 24.0 0.867403 0.953405 0.0466 0.1326 0.8208 0.8297 0.9235 0.9172 0.8946 0.8674  0.9534 0.9196 0.0765 [[157, 24], [13, 266]]\n",
      "      5 167.0 265.0 14.0 14.0 0.922652 0.949821 0.0502 0.0773 0.8725 0.8725 0.9227 0.9498 0.9227 0.9227  0.9498 0.9391 0.0773 [[167, 14], [14, 265]]\n",
      "      6 162.0 270.0  9.0 19.0 0.895028 0.967742 0.0323 0.1050 0.8628 0.8712 0.9474 0.9343 0.9205 0.8950  0.9677 0.9391 0.0526  [[162, 19], [9, 270]]\n",
      "      7 161.0 266.0 13.0 20.0 0.889503 0.953405 0.0466 0.1105 0.8429 0.8487 0.9253 0.9301 0.9070 0.8895  0.9534 0.9283 0.0747 [[161, 20], [13, 266]]\n",
      "      8 167.0 268.0 11.0 14.0 0.922652 0.960573 0.0394 0.0773 0.8832 0.8858 0.9382 0.9504 0.9304 0.9227  0.9606 0.9457 0.0618 [[167, 14], [11, 268]]\n",
      "      9 163.0 271.0  8.0 18.0 0.900552 0.971326 0.0287 0.0994 0.8719 0.8804 0.9532 0.9377 0.9261 0.9006  0.9713 0.9435 0.0468  [[163, 18], [8, 271]]\n",
      "     10 162.0 266.0 13.0 19.0 0.895028 0.953405 0.0466 0.1050 0.8484 0.8534 0.9257 0.9333 0.9101 0.8950  0.9534 0.9304 0.0743 [[162, 19], [13, 266]]\n",
      "Average 163.4 266.5 12.3 17.9 0.901260 0.955879 0.0441 0.0987 0.8571 0.8618 0.9301 0.9372 0.9153 0.9013  0.9559 0.9344 0.0699                    NaN\n"
     ]
    }
   ],
   "source": [
    "# 2. SVM Implementation\n",
    "print(\"\\nSupport Vector Machine Results:\")\n",
    "# Using RBF kernel with optimized parameters\n",
    "svm_classifier = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "svm_results = evaluate_model(svm_classifier, X_scaled, y, \"SVM\")\n",
    "print(svm_results.to_string(index=False, formatters={\n",
    "    'Sens.': '{:.4f}'.format,\n",
    "    'Specif.': '{:.4f}'.format,\n",
    "    'Prec.': '{:.4f}'.format,\n",
    "    'NPV': '{:.4f}'.format,\n",
    "    'FPR': '{:.4f}'.format,\n",
    "    'FDR': '{:.4f}'.format,\n",
    "    'FNR': '{:.4f}'.format,\n",
    "    'Acc.': '{:.4f}'.format,\n",
    "    'F1': '{:.4f}'.format,\n",
    "    'TSS': '{:.4f}'.format,\n",
    "    'HSS': '{:.4f}'.format\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01d2d4",
   "metadata": {},
   "source": [
    "#### The GRU model architecture consists of:\n",
    "* An embedding layer.\n",
    "* A GRU layer with 64 hidden units and 2 layers.\n",
    "* A dense output layer with a sigmoid activation function.\n",
    "\n",
    "The paramaters used are:\n",
    "* Adam Optimizer\n",
    "    * Learning Rate: 0.001\n",
    "    * Binary Cross Entropy Loss\n",
    "* Epochs: 10\n",
    "* Batch size: 32\n",
    "* random_state: 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b0038197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRU Results:\n",
      "   Fold    TP    TN   FP   FN      TPR      TNR    FPR    FNR    TSS    HSS  Precision    NPV     F1  Sensitivity  Specificity  Accuracy    FDR       Confusion Matrix\n",
      "      1 163.0 260.0 19.0 19.0 0.895604 0.931900 0.0681 0.1044 0.8275 0.8275   0.895604 0.9319 0.8956     0.895604     0.931900  0.917570 0.1044 [[163, 19], [19, 260]]\n",
      "      2 169.0 264.0 14.0 13.0 0.928571 0.949640 0.0504 0.0714 0.8782 0.8774   0.923497 0.9531 0.9260     0.928571     0.949640  0.941304 0.0765 [[169, 13], [14, 264]]\n",
      "      3 171.0 261.0 17.0 11.0 0.939560 0.938849 0.0612 0.0604 0.8784 0.8734   0.909574 0.9596 0.9243     0.939560     0.938849  0.939130 0.0904 [[171, 11], [17, 261]]\n",
      "      4 164.0 267.0 12.0 17.0 0.906077 0.956989 0.0430 0.0939 0.8631 0.8673   0.931818 0.9401 0.9188     0.906077     0.956989  0.936957 0.0682 [[164, 17], [12, 267]]\n",
      "      5 174.0 260.0 19.0  7.0 0.961326 0.931900 0.0681 0.0387 0.8932 0.8829   0.901554 0.9738 0.9305     0.961326     0.931900  0.943478 0.0984  [[174, 7], [19, 260]]\n",
      "      6 167.0 265.0 14.0 14.0 0.922652 0.949821 0.0502 0.0773 0.8725 0.8725   0.922652 0.9498 0.9227     0.922652     0.949821  0.939130 0.0773 [[167, 14], [14, 265]]\n",
      "      7 166.0 267.0 12.0 15.0 0.917127 0.956989 0.0430 0.0829 0.8741 0.8767   0.932584 0.9468 0.9248     0.917127     0.956989  0.941304 0.0674 [[166, 15], [12, 267]]\n",
      "      8 165.0 268.0 11.0 16.0 0.911602 0.960573 0.0394 0.0884 0.8722 0.8764   0.937500 0.9437 0.9244     0.911602     0.960573  0.941304 0.0625 [[165, 16], [11, 268]]\n",
      "      9 160.0 274.0  5.0 21.0 0.883978 0.982079 0.0179 0.1160 0.8661 0.8797   0.969697 0.9288 0.9249     0.883978     0.982079  0.943478 0.0303  [[160, 21], [5, 274]]\n",
      "     10 162.0 265.0 14.0 19.0 0.895028 0.949821 0.0502 0.1050 0.8448 0.8490   0.920455 0.9331 0.9076     0.895028     0.949821  0.928261 0.0795 [[162, 19], [14, 265]]\n",
      "Average 166.1 265.1 13.7 15.2 0.916153 0.950856 0.0491 0.0838 0.8670 0.8683   0.924494 0.9461 0.9199     0.916153     0.950856  0.937192 0.0755                    NaN\n"
     ]
    }
   ],
   "source": [
    "# 3. GRU evaluation\n",
    "print(\"\\nGRU Results:\")\n",
    "gru_results = evaluate_gru_model(X_tensor, y_tensor, \"GRU\")\n",
    "print(gru_results.to_string(index=False, formatters={\n",
    "    'Sens.': '{:.4f}'.format,\n",
    "    'Specif.': '{:.4f}'.format,\n",
    "    'Prec.': '{:.4f}'.format,\n",
    "    'NPV': '{:.4f}'.format,\n",
    "    'FPR': '{:.4f}'.format,\n",
    "    'FDR': '{:.4f}'.format,\n",
    "    'FNR': '{:.4f}'.format,\n",
    "    'Acc.': '{:.4f}'.format,\n",
    "    'F1': '{:.4f}'.format,\n",
    "    'TSS': '{:.4f}'.format,\n",
    "    'HSS': '{:.4f}'.format\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03325fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important Features (Random Forest):\n",
      " feature  importance\n",
      "      51    0.122275\n",
      "      52    0.095507\n",
      "       6    0.080334\n",
      "      15    0.063160\n",
      "      54    0.059750\n",
      "      55    0.056913\n",
      "      56    0.051001\n",
      "      24    0.043059\n",
      "      20    0.042029\n",
      "      18    0.033238\n"
     ]
    }
   ],
   "source": [
    "# Show feature importance for Random Forest\n",
    "rf_classifier.fit(X, y)\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': range(X.shape[1]),\n",
    "    'importance': rf_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nTop 10 Most Important Features (Random Forest):\")\n",
    "print(feature_importances.head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
